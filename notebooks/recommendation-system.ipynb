{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2565112,"sourceType":"datasetVersion","datasetId":1049650},{"sourceId":11779185,"sourceType":"datasetVersion","datasetId":7395141}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"arashnic/mind-news-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T09:52:25.883386Z","iopub.execute_input":"2025-05-12T09:52:25.883688Z","iopub.status.idle":"2025-05-12T09:52:28.492929Z","shell.execute_reply.started":"2025-05-12T09:52:25.883638Z","shell.execute_reply":"2025-05-12T09:52:28.492270Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/mind-news-dataset\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"print(articles_df.columns)\nprint(user_histories_df.columns)\nprint(behaviors_df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T08:06:25.683965Z","iopub.execute_input":"2025-05-12T08:06:25.684272Z","iopub.status.idle":"2025-05-12T08:06:25.689003Z","shell.execute_reply.started":"2025-05-12T08:06:25.684249Z","shell.execute_reply":"2025-05-12T08:06:25.688246Z"}},"outputs":[{"name":"stdout","text":"Index(['id', 'category', 'subcategory', 'title', 'abstract', 'url', 'entity',\n       'misc', 'abstract_clean', 'content'],\n      dtype='object')\nIndex(['user_id', 'clicked_articles', 'history'], dtype='object')\nIndex(['impression_id', 'user_id', 'timestamp', 'history', 'impressions',\n       'clicked_articles', 'all_articles'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom collections import defaultdict\nimport ast\nfrom tqdm import tqdm\n\n# === Adjust this path to where kagglehub saved the dataset ===\nDATA_DIR = \"/kaggle/working/arashnic-mind-news-dataset\"  # or wherever your dataset is extracted\n\n# === Load and concatenate news files ===\ndef load_news():\n    dfs = []\n    for split in ['train', 'dev', 'test']:\n        path = os.path.join(DATA_DIR, split, '/kaggle/input/mind-news-dataset/news.tsv/news.tsv')\n        df = pd.read_csv(path, sep='\\t', names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])\n        dfs.append(df)\n    news_df = pd.concat(dfs, ignore_index=True)\n    # Drop duplicates just in case\n    news_df.drop_duplicates(subset=['NewsID'], inplace=True)\n    return news_df\n\n# === Load and concatenate behaviors files ===\ndef load_behaviors():\n    dfs = []\n    for split in ['train', 'dev', 'test']:\n        path = os.path.join(DATA_DIR, split, '/kaggle/input/mind-news-dataset/MINDsmall_train/behaviors.tsv')\n        df = pd.read_csv(path, sep='\\t', names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n        dfs.append(df)\n    behaviors_df = pd.concat(dfs, ignore_index=True)\n    return behaviors_df\n\n# === Parse clicked news from impressions string ===\ndef parse_clicked(impression_str):\n    # impression_str example: \"N12345-1 N23456-0 N34567-1\"\n    clicked = []\n    for item in impression_str.strip().split():\n        try:\n            news_id, click = item.split('-')\n            if click == '1':\n                clicked.append(news_id)\n        except:\n            continue\n    return clicked\n\n# === Parse user history string ===\ndef parse_history(history_str):\n    if pd.isna(history_str) or history_str.strip() == '':\n        return []\n    return history_str.strip().split()\n\n# === Build TF-IDF matrix for news content (title + abstract) ===\ndef build_tfidf(news_df):\n    news_df['content'] = news_df['Title'].fillna('') + \" \" + news_df['Abstract'].fillna('')\n    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n    tfidf_matrix = vectorizer.fit_transform(news_df['content'])\n    return tfidf_matrix, vectorizer\n\n# === Build user profile vectors by averaging clicked news vectors ===\ndef build_user_profiles(behaviors_df, news2idx, tfidf_matrix):\n    user_profiles = {}\n    skipped_no_history = 0\n    for user_id, group in tqdm(behaviors_df.groupby('UserID'), desc=\"Building user profiles\"):\n        # Aggregate all clicked news from history + impressions\n        clicked_news = set()\n        for _, row in group.iterrows():\n            clicked_news.update(parse_history(row['History']))\n            clicked_news.update(parse_clicked(row['Impressions']))\n        # Filter clicked news to those in news2idx\n        valid_indices = [news2idx[nid] for nid in clicked_news if nid in news2idx]\n        if not valid_indices:\n            skipped_no_history += 1\n            continue\n        # Average vectors\n        profile_vec = np.asarray(tfidf_matrix[valid_indices].mean(axis=0)).ravel()\n        user_profiles[user_id] = profile_vec\n    print(f\"Skipped {skipped_no_history} users with no valid clicked news.\")\n    return user_profiles\n\n# === Popularity baseline for fallback recommendations ===\ndef get_popularity(behaviors_df):\n    click_counts = defaultdict(int)\n    for _, row in behaviors_df.iterrows():\n        clicked = parse_clicked(row['Impressions'])\n        for nid in clicked:\n            click_counts[nid] += 1\n    popular_news = [nid for nid, _ in sorted(click_counts.items(), key=lambda x: x[1], reverse=True)]\n    return popular_news\n\n# === Recommend top-k news for a user based on profile vector ===\ndef recommend(user_vec, tfidf_matrix, news_df, news2idx, popular_news, clicked_news_set, k=10):\n    if user_vec is None:\n        recs = [nid for nid in popular_news if nid not in clicked_news_set]\n        return recs[:k]\n    user_vec = np.asarray(user_vec)\n    if user_vec.ndim == 1:\n        user_vec = user_vec.reshape(1, -1)\n    sims = cosine_similarity(user_vec, tfidf_matrix).flatten()\n    top_indices = sims.argsort()[::-1]\n    recs = []\n    \n    for idx in top_indices:\n        nid = news_df.iloc[idx]['NewsID']\n        if nid not in clicked_news_set:\n            recs.append(nid)\n        if len(recs) == k:\n            break\n    # If not enough recs, fill with popular news\n    if len(recs) < k:\n        for nid in popular_news:\n            if nid not in clicked_news_set and nid not in recs:\n                recs.append(nid)\n            if len(recs) == k:\n                break\n    return recs\n\n# === Evaluation metrics ===\ndef precision_at_k(actual, predicted, k):\n    actual_set = set(actual)\n    pred_k = predicted[:k]\n    return len(set(pred_k) & actual_set) / k\n\ndef recall_at_k(actual, predicted, k):\n    actual_set = set(actual)\n    pred_k = predicted[:k]\n    return len(set(pred_k) & actual_set) / len(actual_set) if actual_set else 0\n\ndef ndcg_at_k(actual, predicted, k):\n    actual_set = set(actual)\n    dcg = 0.0\n    for i, p in enumerate(predicted[:k]):\n        if p in actual_set:\n            dcg += 1 / np.log2(i + 2)\n    idcg = sum([1 / np.log2(i + 2) for i in range(min(len(actual_set), k))])\n    return dcg / idcg if idcg > 0 else 0\n\n# === Main pipeline ===\ndef main():\n    print(\"Loading news...\")\n    news_df = load_news()\n    print(f\"Total news articles: {len(news_df)}\")\n\n    print(\"Loading behaviors...\")\n    behaviors_df = load_behaviors()\n    print(f\"Total behavior records: {len(behaviors_df)}\")\n\n    print(\"Building TF-IDF matrix...\")\n    tfidf_matrix, vectorizer = build_tfidf(news_df)\n\n    news2idx = {nid: idx for idx, nid in enumerate(news_df['NewsID'])}\n\n    print(\"Building user profiles...\")\n    user_profiles = build_user_profiles(behaviors_df, news2idx, tfidf_matrix)\n\n    print(\"Calculating popularity baseline...\")\n    popular_news = get_popularity(behaviors_df)\n\n    print(\"Generating recommendations and evaluating...\")\n    precisions, recalls, ndcgs = [], [], []\n    evaluated_users = 0\n    skipped_users = 0\n\n    for user_id, group in tqdm(behaviors_df.groupby('UserID')):\n        # Aggregate clicked news in impressions for evaluation\n        actual_clicked = []\n        for _, row in group.iterrows():\n            actual_clicked.extend(parse_clicked(row['Impressions']))\n        actual_clicked = list(set(actual_clicked))\n        if not actual_clicked:\n            skipped_users += 1\n            continue\n\n        user_vec = user_profiles.get(user_id, None)\n        # Also get clicked news from history + impressions to exclude from recommendations\n        clicked_news = set()\n        for _, row in group.iterrows():\n            clicked_news.update(parse_history(row['History']))\n            clicked_news.update(parse_clicked(row['Impressions']))\n\n        recs = recommend(user_vec, tfidf_matrix, news_df, news2idx, popular_news, clicked_news, k=10)\n\n        precisions.append(precision_at_k(actual_clicked, recs, 10))\n        recalls.append(recall_at_k(actual_clicked, recs, 10))\n        ndcgs.append(ndcg_at_k(actual_clicked, recs, 10))\n        evaluated_users += 1\n\n    # Save recommendations for all users\n    print(\"Saving recommendations for all users...\")\n    recs_output = []\n    for user_id, group in behaviors_df.groupby('UserID'):\n        user_vec = user_profiles.get(user_id, None)\n        clicked_news = set()\n        for _, row in group.iterrows():\n            clicked_news.update(parse_history(row['History']))\n            clicked_news.update(parse_clicked(row['Impressions']))\n        recs = recommend(user_vec, tfidf_matrix, news_df, news2idx, popular_news, clicked_news, k=10)\n        recs_output.append({'user_id': user_id, 'recommended_news_ids': recs})\n\n    recs_df = pd.DataFrame(recs_output)\n    recs_df.to_csv(\"mind_tfidf_recommendations.csv\", index=False)\n    print(\"Recommendations saved to mind_tfidf_recommendations.csv\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T10:45:59.218158Z","iopub.execute_input":"2025-05-12T10:45:59.218764Z","iopub.status.idle":"2025-05-12T11:04:17.850586Z","shell.execute_reply.started":"2025-05-12T10:45:59.218740Z","shell.execute_reply":"2025-05-12T11:04:17.849888Z"}},"outputs":[{"name":"stdout","text":"Loading news...\nTotal news articles: 51282\nLoading behaviors...\nTotal behavior records: 470895\nBuilding TF-IDF matrix...\nBuilding user profiles...\n","output_type":"stream"},{"name":"stderr","text":"Building user profiles: 100%|██████████| 50000/50000 [00:49<00:00, 1005.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Skipped 0 users with no valid clicked news.\nCalculating popularity baseline...\nGenerating recommendations and evaluating...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50000/50000 [09:02<00:00, 92.20it/s] \n","output_type":"stream"},{"name":"stdout","text":"Saving recommendations for all users...\nRecommendations saved to mind_tfidf_recommendations.csv\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# **Evaluation**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport ast\n\n# Load saved recommendations\nrecs_df = pd.read_csv(\"/kaggle/working/mind_tfidf_recommendations.csv\")\n\n# Convert string representation of list back to Python list\ndef parse_recs(rec_str):\n    try:\n        return ast.literal_eval(rec_str)\n    except:\n        return []\n\nrecs_df['recommended_news_ids'] = recs_df['recommended_news_ids'].apply(parse_recs)\n\n# Load behaviors (ground truth)\nbehaviors_df = pd.read_csv(\"/kaggle/input/mind-news-dataset/MINDsmall_train/behaviors.tsv\", sep='\\t', names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n\n# Parsing function for actual clicked news\ndef parse_clicked(impression_str):\n    if pd.isna(impression_str) or impression_str.strip() == '':\n        return []\n    clicked = []\n    for item in impression_str.strip().split():\n        try:\n            news_id, click = item.split('-')\n            if click == '1':\n                clicked.append(news_id)\n        except:\n            continue\n    return clicked\nfrom collections import defaultdict\n\nactual_clicks_per_user = defaultdict(set)\n\nfor _, row in behaviors_df.iterrows():\n    user = row['UserID']\n    clicked = parse_clicked(row['Impressions'])\n    actual_clicks_per_user[user].update(clicked)\ndef hit_rate_at_k(actual, predicted, k):\n    actual_set = set(actual)\n    pred_k = predicted[:k]\n    return 1.0 if len(set(pred_k) & actual_set) > 0 else 0.0\n\ndef mrr_at_k(actual, predicted, k):\n    actual_set = set(actual)\n    for i, p in enumerate(predicted[:k]):\n        if p in actual_set:\n            return 1.0 / (i + 1)\n    return 0.0\nhit_rates = []\nmrrs = []\n\nfor _, row in recs_df.iterrows():\n    user = row['user_id']\n    recs = row['recommended_news_ids']\n    actual = list(actual_clicks_per_user.get(user, []))\n    if not actual:\n        continue  # Skip users with no actual clicks\n    hit_rates.append(hit_rate_at_k(actual, recs, 10))\n    mrrs.append(mrr_at_k(actual, recs, 10))\n\nprint(f\"Hit Rate@10: {sum(hit_rates)/len(hit_rates):.4f}\")\nprint(f\"MRR@10: {sum(mrrs)/len(mrrs):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:04:22.337575Z","iopub.execute_input":"2025-05-12T11:04:22.337873Z","iopub.status.idle":"2025-05-12T11:04:33.823489Z","shell.execute_reply.started":"2025-05-12T11:04:22.337852Z","shell.execute_reply":"2025-05-12T11:04:33.822759Z"}},"outputs":[{"name":"stdout","text":"Hit Rate@10: 0.0000\nMRR@10: 0.0000\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(\"Sample user recommendations and actual clicks:\")\n\nfor _, row in recs_df.head(5).iterrows():\n    user = row['user_id']\n    recs = row['recommended_news_ids']\n    actual = list(actual_clicks_per_user.get(user, []))\n    print(f\"User: {user}\")\n    print(f\"Recommended: {recs}\")\n    print(f\"Actual clicked: {actual}\")\n    print(\"-\" * 40)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:08:17.931562Z","iopub.execute_input":"2025-05-12T11:08:17.932232Z","iopub.status.idle":"2025-05-12T11:08:17.939837Z","shell.execute_reply.started":"2025-05-12T11:08:17.932204Z","shell.execute_reply":"2025-05-12T11:08:17.938981Z"}},"outputs":[{"name":"stdout","text":"Sample user recommendations and actual clicks:\nUser: U100\nRecommended: ['N13927', 'N19429', 'N52303', 'N64622', 'N42746', 'N6464', 'N28081', 'N12412', 'N19267', 'N19285']\nActual clicked: ['N7800']\n----------------------------------------\nUser: U1000\nRecommended: ['N6785', 'N39535', 'N23084', 'N51257', 'N41835', 'N50553', 'N45324', 'N60374', 'N17196', 'N288']\nActual clicked: ['N29739', 'N53875', 'N58656', 'N7670']\n----------------------------------------\nUser: U10001\nRecommended: ['N6482', 'N4812', 'N54662', 'N19893', 'N6677', 'N58090', 'N17668', 'N55172', 'N60064', 'N28219']\nActual clicked: ['N10833', 'N35937', 'N1031']\n----------------------------------------\nUser: U10003\nRecommended: ['N64773', 'N36602', 'N45970', 'N43123', 'N30269', 'N46921', 'N11971', 'N31681', 'N63706', 'N38758']\nActual clicked: ['N57090', 'N18708', 'N55689']\n----------------------------------------\nUser: U10008\nRecommended: ['N49034', 'N1178', 'N56411', 'N46773', 'N23886', 'N31129', 'N13692', 'N21631', 'N15809', 'N29314']\nActual clicked: ['N15405']\n----------------------------------------\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"def normalize_ids(id_list):\n    return set(str(i).strip().upper() for i in id_list if i)\n\n# When you compare:\nactual_norm = normalize_ids(actual)\nrec_norm = normalize_ids(recs)\noverlap = actual_norm & rec_norm\nprint(f\"Overlap: {overlap}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:17:58.810167Z","iopub.execute_input":"2025-05-12T11:17:58.810697Z","iopub.status.idle":"2025-05-12T11:17:58.815360Z","shell.execute_reply.started":"2025-05-12T11:17:58.810672Z","shell.execute_reply":"2025-05-12T11:17:58.814586Z"}},"outputs":[{"name":"stdout","text":"Overlap: set()\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"for _, row in behaviors_df.head(5).iterrows():\n    print(f\"User {row['UserID']} clicked: {parse_clicked(row['Impressions'])}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T11:18:21.696951Z","iopub.execute_input":"2025-05-12T11:18:21.697767Z","iopub.status.idle":"2025-05-12T11:18:21.703118Z","shell.execute_reply.started":"2025-05-12T11:18:21.697739Z","shell.execute_reply":"2025-05-12T11:18:21.702325Z"}},"outputs":[{"name":"stdout","text":"User U13740 clicked: ['N55689']\nUser U91836 clicked: ['N17059']\nUser U73700 clicked: ['N23814']\nUser U34670 clicked: ['N49685']\nUser U8125 clicked: ['N8400']\n","output_type":"stream"}],"execution_count":30}]}